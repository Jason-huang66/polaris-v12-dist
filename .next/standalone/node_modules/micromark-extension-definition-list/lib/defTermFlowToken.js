import { splice } from 'micromark-util-chunked';
import { tokenTypes } from './types.js';
import { formatEvents } from './utils.js';
export function analyzeDefTermFlow(flowToken) {
  const flowEvents = flowToken._tokenizer.events;
  let paraEnterIndex;
  let paraExitIndex;
  let paraStartOffset;

  for (let i = flowEvents.length - 1; i >= 0; i--) {
    const tmpEvent = flowEvents[i];

    if (tmpEvent[1].type === "paragraph") {
      if (tmpEvent[0] === 'exit') paraExitIndex = i;else {
        paraEnterIndex = i;
        paraStartOffset = tmpEvent[1].start.offset;

        for (let j = i - 1; j >= 0; j--) {
          const e = flowEvents[j];

          if (e[1].type === "content") {
            continue;
          }

          if (e[1].type === "linePrefix") {
            paraStartOffset = e[1].start.offset;
            break;
          }

          break;
        }

        break;
      }
    }
  }

  if (paraEnterIndex != null && paraExitIndex != null && paraStartOffset != null) {
    return {
      flowEvents,
      paragraph: {
        enterIndex: paraEnterIndex,
        exitIndex: paraExitIndex,
        startOffset: paraStartOffset
      }
    };
  } else {
    return {
      flowEvents
    };
  }
}

function getSubtokensForDefTerm(termFlowToken) {
  const flowEvents = termFlowToken._tokenizer.events;
  const leadingChildEvents = [];
  const trailingChildEvents = [];
  const termChildEvents = [];
  const removedEventIndexes = [];
  let pEnterIndex;
  let pExitIndex;
  let contentEnterIndex;
  let contentExitIndex;
  const paragraphEvents = [];
  const contentEvents = [];

  for (let i = flowEvents.length - 1; i >= 0; i--) {
    const tmpEvent = flowEvents[i];
    const tmpToken = tmpEvent[1];

    if (tmpToken.start.offset >= termFlowToken.end.offset) {
      removedEventIndexes.push(i);
      continue;
    }

    switch (tmpToken.type) {
      case "paragraph":
        if (pEnterIndex == null && tmpEvent[0] === 'enter') pEnterIndex = i;else if (pExitIndex == null && tmpEvent[0] === 'exit') pExitIndex = i;
        break;

      case "content":
        if (tmpEvent[0] === 'enter') contentEnterIndex = i;else if (tmpEvent[0] === 'exit') contentExitIndex = i;
        break;

      default:
        if (termFlowToken.start.offset <= tmpToken.start.offset && tmpToken.end.offset <= termFlowToken.end.offset) {
          if (tmpToken.type === "chunkText") {
            // unlink chunkText token
            if (tmpToken.previous && tmpToken.previous.start.offset < termFlowToken.start.offset) {
              tmpToken.previous.next = undefined;
              tmpToken.previous = undefined;
            }

            if (tmpToken.next && termFlowToken.end.offset < tmpToken.next.end.offset) {
              tmpToken.next.previous = undefined;
              tmpToken.next = undefined;
            }
          }

          if (pEnterIndex == null && pExitIndex == null) trailingChildEvents.unshift(tmpEvent);else if (pEnterIndex == null && pExitIndex != null) termChildEvents.unshift(tmpEvent);else leadingChildEvents.unshift(tmpEvent);
          removedEventIndexes.push(i);
        } else {
          if (pEnterIndex == null && pExitIndex != null) paragraphEvents.unshift(tmpEvent);
          if (contentEnterIndex == null && contentExitIndex != null) contentEvents.unshift(tmpEvent);
        }

    }

    if (tmpToken.end.offset <= termFlowToken.start.offset) break;
  } // modify paragraph and content


  if (pExitIndex != null) {
    if (paragraphEvents.length >= 1) {
      // adjust end position
      flowEvents[pExitIndex][1].end = Object.assign({}, paragraphEvents[paragraphEvents.length - 1][1].end);
    } else if (pEnterIndex != null) {
      // remove paragraph
      removedEventIndexes.push(pEnterIndex, pExitIndex);
    }
  }

  if (contentExitIndex != null) {
    if (contentEvents.length >= 1) {
      // adjust end position
      flowEvents[contentExitIndex][1].end = Object.assign({}, contentEvents[contentEvents.length - 1][1].end);
    } else if (contentEnterIndex != null) {
      // remove content
      removedEventIndexes.push(contentEnterIndex, contentExitIndex);
    }
  } // remove subtokens from original flowEvents


  removedEventIndexes.sort((a, b) => b - a);

  for (const i of removedEventIndexes) {
    splice(flowEvents, i, 1, []);
  }

  return {
    leadingChildEvents,
    termChildEvents,
    trailingChildEvents
  };
}

export function subtokenizeDefTerm(events, flowEnterIndex, flowExitIndex) {
  /**
   * Subtokenize chunkFlow events
   */
  const termFlowToken = events[flowEnterIndex][1];

  // unlink
  if (termFlowToken.previous != null) {
    termFlowToken.previous.next = undefined;
    termFlowToken.previous = undefined;
  } // get subtokens


  const subtokens = getSubtokensForDefTerm(termFlowToken); // subtokenize chunkFlow event with childEvents

  const context = events[flowExitIndex][2];
  const childEvents = [];
  const numOfChildren = subtokens.termChildEvents.length;

  if (numOfChildren > 0) {
    const termToken = {
      type: tokenTypes.defListTerm,
      start: Object.assign({}, termFlowToken.start),
      end: Object.assign({}, termFlowToken.end)
    };
    childEvents.push(['enter', termToken, context]);
    childEvents.push(...subtokens.leadingChildEvents);
    childEvents.push(...subtokens.termChildEvents);
    childEvents.push(...subtokens.trailingChildEvents);
    childEvents.push(['exit', termToken, context]);
  } else {
    childEvents.push(...subtokens.leadingChildEvents);
    childEvents.push(...subtokens.trailingChildEvents);
  }

  splice(events, flowExitIndex, 1, []);
  splice(events, flowEnterIndex, 1, childEvents);
  return events;
}